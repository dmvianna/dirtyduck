#+STARTUP: showeverything
#+STARTUP: nohideblocks
#+STARTUP: indent
#+PROPERTY: header-args:sql :engine postgresql
#+PROPERTY: header-args:sql+ :dbhost 0.0.0.0
#+PROPERTY: header-args:sql+ :dbport 5434
#+PROPERTY: header-args:sql+ :dbuser food_user
#+PROPERTY: header-args:sql+ :dbpassword some_password
#+PROPERTY: header-args:sql+ :database food
#+PROPERTY: header-args:sql+ :results table drawer
#+PROPERTY: header-args:sh  :results verbatim org
#+PROPERTY: header-args:sh+ :prologue exec 2>&1 :epilogue :


* Data preparation

We need to get the data and transform it into a shape that is suitable for the analysis.

*NOTE* Unless we say otherwise, you should run all the following commands inside =bastion=.

** Downloading the data

The data can be downloaded from the City of Chicago's open data portal. The following command downloads the data and stores it as a =csv= file in the =data/= folder: 

   #+BEGIN_SRC sh :dir /docker:root@tutorial_bastion:/ :results none
     curl "https://data.cityofchicago.org/api/views/4ijn-s7e5/rows.csv?accessType=DOWNLOAD" > data/inspections.csv
   #+END_SRC

We can check the size of the file:[fn:1]

   #+BEGIN_SRC sh :dir /docker:root@tutorial_bastion:/ 
     ls -lh /data
   #+END_SRC

   #+RESULTS:
   #+BEGIN_SRC org
   total 189M
   -rw-rw-r-- 1 1000 1000 189M Mar  3 21:39 inspections.csv
   #+END_SRC

And the (apparent) number of rows:[fn:2]

   #+BEGIN_SRC sh :dir /docker:root@tutorial_bastion:/ 
     wc -l /data/inspections.csv
   #+END_SRC

   #+RESULTS:
   #+BEGIN_SRC org
   402526 /data/inspections.csv
   #+END_SRC

Remember this number because you'll get a surprise when you load the data into the database.

** Loading data into the database

Before loading =inspections.csv= into the database, verify that the database table is empty:[fn:3]

   #+BEGIN_SRC sh :dir /docker:root@tutorial_bastion:/ 
     psql ${FOOD_DB_URL} -c 'select count(*) from raw.inspections'
   #+END_SRC

   #+RESULTS:
   #+BEGIN_SRC org
    count 
   -------
        0
   (1 row)

   #+END_SRC

We can load the file using the =\copy= command. The command's output will report how many rows were inserted:

   #+BEGIN_SRC sh :dir /docker:root@tutorial_bastion:/
     psql ${FOOD_DB_URL} -c "\copy raw.inspections FROM '/data/inspections.csv' WITH HEADER CSV"
   #+END_SRC

   #+RESULTS:
   #+BEGIN_SRC org
   COPY 165597
   #+END_SRC

This is different than the number of rows that we calculated
previously! Did we miss several thousand rows? 

The explanation for this mismatch is that the column
=violations= contains several lines in some examples[fn:4]. But don't worry:
the previous command took care about that.

Let's peek at the data:

   #+BEGIN_SRC sql
select * from raw.inspections limit 1
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   | inspection | dba_name   | aka_name   | license_num | facility_type | risk          | address            | city    | state |   zip |       date | type    | results   | violations |          latitude |          longitude | location                                |
   |------------+-----------+-----------+------------+--------------+---------------+--------------------+---------+-------+-------+------------+---------+-----------+------------+-------------------+--------------------+-----------------------------------------|
   |    2145741 | 1914 CLUB | 1914 CLUB |    2569448 | [NULL]       | Risk 1 (High) | 1060 W ADDISON AVE | CHICAGO | IL    | 60613 | 2018-03-01 | License | Not Ready | [NULL]     | 41.94731748901495 | -87.65641794764645 | (41.94731748901495, -87.65641794764645) |
   :END:

Ok, now you have some data loaded! But we still need to /munge/ it to use it in our Machine learning task.

** Transforming (and cleaning) the data

*** Rationale
To tackle a Machine Learning problem, you need to identify the
*entities* of your problem domain, and if your problem involves time,
how those entities change over time, i.e. which *events* happened to
that entity or which *events* where acted by the entity in question.

We will materialize that conceptualization in two different tables, one for entities and
one for events, we will name those tables as =entities= and =events= respectively.

The entity is the *restaurant*, and the events that happen to that entity
are the *inspections*.

The table =entities= should contain an unique identifier for the entity,
some data specific for that entity (like name, age, status). The
=events= table will include data related to the description of the
inspection, but don't forget the two most important attributes of an
event are its spatial position and its temporal location.

Before starting the cleaning, you should know one of the golden rules
-that will make your life easier:

#+BEGIN_QUOTE
   /You must not change your original data/
#+END_QUOTE

The reason for this is the following: if you make some mistake, or if
you want to try a different transformation on your data, you could
always can go back to this =raw= data and start over.

The transformation "road" that we will take in this tutorial is as follows:

1. We put an exact copy of our inse data in the =raw= schema. (We just
   did that)
2. We will apply some simple transformations that will clean our data
   and we will store that version on the =cleaned= schema.
3. We will organize the data semantically in two /unnormalized/[fn:5] tables:
   =events= and =entities= in the =semantic= schema.
4. Then We need to fulfill some =triage= idiosyncrasies, and create
   some other tables and store them in the schema =triage=.
5. Finally, =triage= will take over, and it will create the schema =results=.


#+ATTR_ORG: :width 600 :height 400
#+ATTR_HTML: :width 600 :height 800
#+ATTR_LATEX: :width 400 :height 500
#+RESULTS: data_road
[[file:images/data_road.png]]



*** Dataset documentation

The Chicago's food inspection  dataset has some documentation located
[[https://data.cityofchicago.org/api/assets/BAD5301B-681A-4202-9D25-51B2CAE672FF?download=true][here]]. From it, we can make sense about the column's meaning, and the
process that generates the data.

The meaning of interesting columns follows[fn:6], all the other
columns should be self-explanatory

- *Risk category of facility* (=risk=) ::

#+BEGIN_QUOTE
     Each establishment is categorized as
     to its risk of adversely affecting the public’s health, with 1
     being the highest and 3 the lowest. The frequency of
     inspection is tied to this risk, with risk 1 establishments
     inspected most frequently and risk 3 least frequently.
#+END_QUOTE
   
- *Inspection type* (=type=) ::

#+BEGIN_QUOTE
     An inspection can be one of the following
     types: canvass, the most common type of inspection performed
     at a frequency relative to the risk of the   establishment;
     consultation, when the inspection is  done at the request of the
     owner prior to the opening of the establishment; complaint, when
     the inspection is done in    response to a complaint against the
     establishment; license, when the inspection is done    as a
     requirement for the establishment to receive its license to
     operate; suspect food    poisoning, when the inspection is done
     in response to one or more persons claiming to    have gotten ill
     as a result of eating at the establishment (a specific type of
     complaint-   based inspection); task-force inspection, when an
     inspection of a bar or tavern is done.    Re-inspections can
     occur for most types of these inspections and are indicated as
     such.
#+END_QUOTE

- *Results* (=results=) ::
     
#+BEGIN_QUOTE
     An inspection can pass, pass with conditions or
     fail. Establishments receiving a ‘pass’ were found to have no
     critical or serious violations (violation number 1-14 and 15-29,
     respectively). Establishments receiving a ‘pass  with conditions’
     were found to have critical or serious violations, but these were
     corrected during the inspection. Establishments receiving a
     ‘fail’ were found to have critical or serious violations that
     were not correctable during the inspection. An establishment
     receiving a ‘fail’ does not  necessarily mean the establishment’s
     licensed is suspended. Establishments found to be out of business
     or not located are indicated as such.
#+END_QUOTE
     
- *Violations* (=violations=) ::

#+BEGIN_QUOTE
     An establishment can receive *one or more* of 45
     distinct violations (violation numbers 1-44 and 70). For each
     violation number listed for a given establishment, /the
     requirement the establishment must meet in order for it/ to *NOT*
     /receive a violation is noted, followed by a specific description
     of the findings that caused the violation to be issued/.
#+END_QUOTE
     
We added emphasis to the last one.

From this definitions, we can deduct the following claims:

1. /risk/ is related to the frequency of inspections of type /canvass/.
2. /consultation/ is a compulsory inspections /before/ the facility opens
   (so we can remove it from the data), the same happens with /license/.
3. /complaint/ and /suspect food poisoning/ are types of inspections
   which are  triggered by the people.
4. Inspection of type /consultation/ are triggered by the owner of the
   facility.
5. /task-force/ occurs against bar or taverns.
6. *Critical violations* are coded between =1-14=, *serious violations*
   between =15-29=. So, we can assume that the violations code =30= and
   onward are /minor/ violations.
7. The description of the violation is actually what *shouldn't* found,
   the comment are the steps that the facility should take in order of
   not receive the violation.
8. They are only three possible results of the inspection (plus the
   fact that the facility was not located or out of business).
9. There are several =violations= per =inspection=.



*** Reality check

It is important verify that the documentation is correct. Let's start
checking that the =risk= column *only* have three different classifications:

*NOTE* Execute this in =psql= inside the container =bastion=.

#+BEGIN_SRC sql
  select risk, count(*) from raw.inspections group by risk order by count(*) desc
#+END_SRC

#+RESULTS:
:RESULTS:
| risk            |  count |
|-----------------+--------|
| Risk 1 (High)   | 116039 |
| Risk 2 (Medium) |  34012 |
| Risk 3 (Low)    |  15457 |
| [NULL]          |     66 |
| All             |     23 |
:END:

Ok, we got two more =risk= types: =All= and =NULL= for a grand total
of *5*. 

What about =types= of inspections?

#+BEGIN_SRC sql
  select count(distinct type) from raw.inspections
#+END_SRC

#+RESULTS:
:RESULTS:
| count |
|-------|
|   108 |
:END:

Wow, we got *108* types of inspections instead of *5*.

Which are those types? How bad is it?

#+BEGIN_SRC sql
select type, count(*) from raw.inspections group by type order by count(*) desc limit 10
#+END_SRC

#+RESULTS:
:RESULTS:
| type                     | count |
|--------------------------+-------|
| Canvass                  | 87871 |
| License                  | 21119 |
| Canvass Re-Inspection    | 17010 |
| Complaint                | 14979 |
| License Re-Inspection    |  7598 |
| Complaint Re-Inspection  |  6123 |
| Short Form Complaint     |  6066 |
| Suspected Food Poisoning |   735 |
| Consultation             |   667 |
| License-Task Force       |   605 |
:END:

This columns will require also cleaning. Finally, let's look =results=
(should be 3)

#+BEGIN_SRC  sql
  select results, count(*) from raw.inspections group by results order by count(*) desc
#+END_SRC

#+RESULTS:
:RESULTS:
| results              | count |
|----------------------+-------|
| Pass                 | 96686 |
| Fail                 | 31939 |
| Pass w/ Conditions   | 15625 |
| Out of Business      | 14743 |
| No Entry             |  4877 |
| Not Ready            |  1052 |
| Business Not Located |    61 |
:END:

Ok, disheartening. But, that is the reality of /real/ data. We will try to clean this mess.

*** Cleaning

Let's see the data to figure out how we need to be transform it. We
will concentrate at first in all columns except =violations=, we will
deal with that later, since is more complex.

First, we will remove superfluous spaces and will transform the columns
=type, results, dba_name, aka_name, facility_type, address, city= to
lower case, also, we will clean =risk= keeping only the description
(e.g. *high* instead of *Risk 1 (High)*).

We still need to clean the column =type= (it contains several more
variations instead of the *seven* mentioned in the documentation:
/canvass/, /complaint/, /license/, /re-inspection/, /task-force/, /consultation/
and /suspect food poisoning/). For simplicity, we will use /regular
expressions/ and we will ignore /re-inspection/.

For the column =risk= , we will impute as =high= all the =NULL= and =All=
values.

As we have seen (and we will continue see that)  through all this
tutorial, /data is always messy/, for example, in the column =dba_name=
 we have several different spellings: =SUBWAY= and
=Subway=, =MCDONALDS= and =MC DONALD'S=, =DUNKIN DONUTS/BASKIN ROBBINS= and
=DUNKIN DONUTS / BASKIN ROBBINS=, etc.

We could try a very simple cleaning strategy: convert all the
names to lowercase, remove the trailing spaces, remove the apostrophe
"='"= and remove the spaces around "=/=". The problem with this approach
is that we will be fixing the names that we just saw, but there are
several other nuances down that list. Another approach is use [[https://www.postgresql.org/docs/current/static/fuzzystrmatch.html][soundex]],
but that will (potentially) create a lot of mismatches. The real workaround is apply
some /machine learning/ to /deduplicate/ the entities[fn:7].  We wont follow that
path here, we will stick with first alternative.

Let's review the status of the spatial columns (=state, city, zip, latitude,
longitude=). Beginning with the =state=, all the facilities in the
data should be located at *Ilinois*:

#+begin_src sql
select state, count(*) from raw.inspections group by state
#+end_src

#+RESULTS:
:RESULTS:
| state  |  count |
|--------+--------|
| IL     | 165575 |
| [NULL] |     22 |
:END:

Ok, almost correct, there are some =NULL= values. We will assume that
the =NULL= values are actually =IL= (We will impute them). Moving on
the next spatial column, We expect that all the values in the column
=city= are Chicago[fn:8]: 

#+BEGIN_SRC sql
select 
lower(city) as city, 
count(*) 
from raw.inspections 
group by lower(city) 
order by count(*) desc limit 10
#+END_SRC

#+RESULTS:
:RESULTS:
| city              |  count |
|-------------------+--------|
| chicago           | 165221 |
| [NULL]            |    148 |
| cchicago          |     42 |
| schaumburg        |     20 |
| maywood           |     16 |
| elk grove village |     12 |
| chicagochicago    |      9 |
| chestnut street   |      8 |
| evanston          |      8 |
| inactive          |      8 |
:END:

Oh boy. There are 140-ish rows with =NULL= values and forty-ish rows with the
value =cchicago=, some more down the list, we got even
=chicagochicago=. The rest value are different counties, but all of
them are near to Chicago. We will ignore this column (or equivalently,
we will assume that all the records are from Chicago. 

The zip code has a similar =NULL= problem:

#+BEGIN_SRC sql
select count(*) from raw.inspections where zip is null or btrim(zip) = ''
#+END_SRC

#+RESULTS:
:RESULTS:
| count |
|-------|
|    72 |
:END:

We could attempt to remove this =NULLs= using the location point or
using similar names of restaurants, but for this tutorial we will
remove them. Also, we will convert the coordinates latitude and
longitude to a =Point= [fn:10] [fn:9]. 

Continuing with the cleaning, we will drop the columns =state=,
=latitude=, =longitude= (since these are (now) redundant, because the
=Point= object). We will remove the column =city= since almost
everything happens in Chicago (this is the Chicago's food inspection data set anyway).

So, if you keep the counting, we are only keeping two columns related
to the spatial location of the events: the administrative one
(=zip_code=) and the exact point of the facility (=location=).

There are several violations inspected per event, for clarity we will
put the violations in their own table.

As a final step in the cleaning we will change the name of the columns
for explicit or better names(e.g =results -> result, dba_name -> facility=, etc).

We will create a new =schema= called =cleaned=. The objective of this
schema is twofold: keep our raw data /as-is/ and store our assumptions
and cleaning decisions separated from the /raw/ data in a schema that
/semantically/ is transmitting the information: "this is our clean
data".

The =cleaned= schema will contain two tables: =cleaned.inspections=
and =cleaned.violations=. 


#+BEGIN_SRC sql :tangle ./sql/create_cleaned_inspections_table.sql
  create schema if not exists cleaned;
#+END_SRC

#+RESULTS:

Then, we will create our mini *ETL* with our cleaning decisions:

#+BEGIN_SRC sql :tangle ./sql/create_cleaned_inspections_table.sql
drop table if exists cleaned.inspections cascade;

create table cleaned.inspections as (
with cleaned as (
select
inspection::integer,
btrim(lower(results)) as result, 
license_num::integer,
btrim(lower(dba_name)) as facility,
btrim(lower(aka_name)) as facility_aka,
case when
facility_type is null then 'unknown'
else btrim(lower(facility_type))
end as facility_type,
lower(substring(risk from '\((.+)\)')) as risk,
btrim(lower(address)) as address,
zip as zip_code,
substring(
btrim(lower(regexp_replace(type, 'liquor', 'task force', 'gi')))
from 'canvass|task force|complaint|food poisoning|consultation|license|tag removal') as type,
date,
ST_SetSRID(ST_MakePoint(longitude, latitude), 4326)::geography as location  -- We use geography so the measurements are in meters
from raw.inspections
where zip is not null  -- removing NULL zip codes
)

select * from cleaned where type is not null
);
#+END_SRC

#+RESULTS:

You could execute this code using (if you are not connected to the
database with =psql=):

#+BEGIN_SRC sh :dir /docker:root@tutorial_bastion:/ :results org drawer
psql ${FOOD_DB_URL} < /sql/create_cleaned_inspections_table.sql
#+END_SRC

#+RESULTS:
:RESULTS:
SELECT 164178
:END:

Or, if you are in =psql=

#+BEGIN_EXAMPLE sql
\i /code/create_cleaned_inspections_table.sql
#+END_EXAMPLE

The number of inspections now is:

#+BEGIN_SRC sql 
 select count(inspection) from cleaned.inspections;
#+END_SRC

#+RESULTS:
:RESULTS:
|  count |
|--------|
| 164790 |
:End:

Note that  src_sh[:results raw  :export result :dir
 /docker:root@tutorial_bastion:/]{psql ${FOOD_DB_URL}  -t -P
 format=unaligned  -c 'select count(inspection) from
 cleaned.inspections'} 164790
 is smaller than src_sh[:results raw  :export result :dir
 /docker:root@tutorial_bastion:/]{psql ${FOOD_DB_URL}  -t -P
 format=unaligned  -c 'select count(*) from
 raw.inspections'} 165597, as expected we throw away some inspections.

With the =cleaned.inspections= table created, let's look closer the
column =violations= to choose which steps we should take to clean it.

The first thing to note is that the column =violation= has a lot of information:
it mixes the official code and name of the /requirement to met/ (see the
 [[Dataset documentation]]), followed by inspector's comments. The
comments are free text, that means that they can contain line breaks,
mispellings, etc. If there are more that one violation, they will be
separated using a pipe: =|=.

The following =sql= code removes line breaks and multiple spaces and
creates an array with all the violations of the inspection number =2145736=

#+BEGIN_SRC sql 
select 
string_to_array(regexp_replace(violations, '[\n\r]+', ' ', 'g' ), '|')  as violations_array
from raw.inspections where inspection = '2145736'
#+END_SRC

#+RESULTS:
:RESULTS:
| violations_array                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |
|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| {"35. WALLS, CEILINGS, ATTACHED EQUIPMENT CONSTRUCTED PER CODE: GOOD REPAIR, SURFACES CLEAN AND DUST-LESS CLEANING METHODS - Comments: MISSING PART OF THE COVING(BASEBOARD) BY THE EXPOSED HAND SINK IN THE KITCHEN. MUST REPAIR AND MAINTAIN. WATER STAINED CEILING TILES IN THE LUNCH ROOM. MUST REPLACE CEILING TILES AND MAINTAIN. PEELING PAINT ON THE CEILING AND WALLS THROUGHOUT THE SCHOOL. HALLWAYS, INSIDE THE CLASSROOMS, INSIDE THE WASHROOMS IN ALL FLOORS. INSTRUCTED TO SCRAPE PEELING PAINT AND RE PAINT.     "," 32. FOOD AND NON-FOOD CONTACT SURFACES PROPERLY DESIGNED, CONSTRUCTED AND MAINTAINED - Comments: FIRST FLOOR GIRL'S WASHROOM,MIDDLE WASHBOWL SINK FAUCET NOT IN GOOD REPAIR, MUST REPAIR AND MAINTAIN. ONE OUT OF TWO HAND DRYER NOT WORKING IN THE FOLLOWING WASHROOM: FIRST FLOOR  BOY'S AND GIRL'S WASHROOM, AND  BOY'S AND GIRL'S WASHROOM 2ND FLOOR. MUST REPAIR AND MAINTAIN. "," 34. FLOORS: CONSTRUCTED PER CODE, CLEANED, GOOD REPAIR, COVING INSTALLED, DUST-LESS CLEANING METHODS USED - Comments: DAMAGED FLOOR INSIDE THE BOY'S AND GIRL'S WASHROOM 2ND FLOOR. MUST REPAIR, MAKE THE FLOOR SMOOTH EASILY CLEANABLE."} |
:END:

The structure of the =violations= column is (check the previous output):

   - If there are several violations reported, those violations will
     be separated by ='|'= 
   - Every violation begins with a code and  a description
   - Every violation could have *comments*, those comments appear after
     the string =- Comments:=

We will take that observations in account and create a new table
called =cleaned.violations= to store

   - inspection
   - code
   - description
   - comments

#+BEGIN_SRC sql :tangle ./sql/create_violations_table.sql
   drop table if exists cleaned.violations cascade;

   create table cleaned.violations as (
   select
   inspection::integer,
   license_num::integer, 
   date::date,
   btrim(tuple[1]) as code,
   btrim(tuple[2]) as description,
   btrim(tuple[3]) as comment,
   (case
     when btrim(tuple[1]) = '' then NULL 
     when btrim(tuple[1])::int between 1 and 14 then 'critical' -- From the documentation
     when btrim(tuple[1])::int between 15 and 29  then 'serious'
     else 'minor'
   end
   ) as severity from
   (
   select
   inspection,
   license_num,
   date,
   regexp_split_to_array(   -- Create an array we will split the code, description, comment
     regexp_split_to_table( -- Create a row per each comment we split by |
       coalesce(            -- If there isn't a violation add '- Comments:'
         regexp_replace(violations, '[\n\r]+', '', 'g' )  -- Remove line breaks
       , '- Comments:')
     , '\|')  -- Split the violations
   , '(?<=\d+)\.\s*|\s*-\s*Comments:')  -- Split each violation in three 
    as tuple
   from raw.inspections
   where results in ('Fail', 'Pass', 'Pass w/ Conditions') and license_num is not null
   ) as t
   );
#+END_SRC

#+Results:
 
This code is in =/sql/create_violations_table.sql=, you can Execute
 it as before.

We can verify the result of the previous Script

#+BEGIN_SRC sql
select * from cleaned.violations 
where inspection = 2145736
#+END_SRC

#+RESULTS:
:RESULTS:
| inspection | license_num |       date | code | description                                                                                                          | comment                                                                                                                                                                                                                                                                                                                                                                            | severity |
|------------+------------+------------+------+----------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------|
|    2145736 |      23591 | 2018-03-01 |   35 | WALLS, CEILINGS, ATTACHED EQUIPMENT CONSTRUCTED PER CODE: GOOD REPAIR, SURFACES CLEAN AND DUST-LESS CLEANING METHODS | MISSING PART OF THE COVING(BASEBOARD) BY THE EXPOSED HAND SINK IN THE KITCHEN. MUST REPAIR AND MAINTAIN.WATER STAINED CEILING TILES IN THE LUNCH ROOM. MUST REPLACE CEILING TILES AND MAINTAIN.PEELING PAINT ON THE CEILING AND WALLS THROUGHOUT THE SCHOOL. HALLWAYS, INSIDE THE CLASSROOMS, INSIDE THE WASHROOMS IN ALL FLOORS. INSTRUCTED TO SCRAPE PEELING PAINT AND RE PAINT. | minor    |
|    2145736 |      23591 | 2018-03-01 |   32 | FOOD AND NON-FOOD CONTACT SURFACES PROPERLY DESIGNED, CONSTRUCTED AND MAINTAINED                                     | FIRST FLOOR GIRL'S WASHROOM,MIDDLE WASHBOWL SINK FAUCET NOT IN GOOD REPAIR, MUST REPAIR AND MAINTAIN.ONE OUT OF TWO HAND DRYER NOT WORKING IN THE FOLLOWING WASHROOM:FIRST FLOOR  BOY'S AND GIRL'S WASHROOM, AND  BOY'S AND GIRL'S WASHROOM 2ND FLOOR. MUST REPAIR AND MAINTAIN.                                                                                                   | minor    |
|    2145736 |      23591 | 2018-03-01 |   34 | FLOORS: CONSTRUCTED PER CODE, CLEANED, GOOD REPAIR, COVING INSTALLED, DUST-LESS CLEANING METHODS USED                | DAMAGED FLOOR INSIDE THE BOY'S AND GIRL'S WASHROOM 2ND FLOOR. MUST REPAIR, MAKE THE FLOOR SMOOTH EASILY CLEANABLE.                                                                                                                                                                                                                                                                 | minor    |
:END:


If everything worked correctly you should be able to run the following code:

#+BEGIN_SRC sql
  select
  case when grouping(severity) = 1 then 'TOTAL' else severity end as severity,
  count(*) from cleaned.violations
  group by rollup (severity)
  order by severity nulls first
#+END_SRC

#+RESULTS:
:RESULTS:
| severity |  count |
|----------+--------|
| [NULL]   |  12952 |
| critical |  39120 |
| minor    | 488954 |
| serious  |  79242 |
| TOTAL    | 620268 |
:END:

As a last step, we should create from the cleaned tables the =entities=
and =events= table.

** Semantic tables

*** Entities table

The =entities= table should uniquely identify each one of the facilities and contain
the attributes that describes each one of them. First, we should
investigate how we can identify uniquely a facility. Let's hope that
this is easy.

We could expect that =license_num= is the way to go for uniquely
identify the facility, let's confirm this with some queries.

We will beging with the following query: /What are the top 5 licenses with more inspections?/

#+BEGIN_SRC sql
    select
    license_num, 
    count(*) as total_inspections,
    coalesce(count(*) filter (where result = 'fail'), 0)
    as total_failures
    from cleaned.inspections
    group by license_num
    order by total_inspections desc
    limit 5;
#+END_SRC

#+RESULTS:
:RESULTS:
| license_num | total_inspections | total_failures |
|------------+------------------+---------------|
|          0 |              420 |           111 |
|    1354323 |              192 |             1 |
|      14616 |              172 |            30 |
|    1574001 |               80 |             4 |
|    1974745 |               59 |             3 |
:END:


This looks weird, there are three license  numbers than concentrates
 most of the inspections (in particular license number =0=) Let's
 investigate a little about the =license_num= = =0=. 

#+BEGIN_SRC sql
  select
  facility_type, count(*) as total_inspections,
  coalesce(count(*) filter (where result = 'fail'), 0)
  as total_failures
  from cleaned.inspections
  where license_num=0
  group by  facility_type
  order by total_inspections desc
  limit 10
#+END_SRC

#+RESULTS:
:RESULTS:
| facility_type    | total_inspections | total_failures |
|-----------------+------------------+---------------|
| restaurant      |              101 |            43 |
| special event   |               61 |             8 |
| unknown         |               43 |            10 |
| shelter         |               31 |             6 |
| navy pier kiosk |               30 |             4 |
| church          |               28 |             3 |
| grocery store   |               16 |             7 |
| church kitchen  |               14 |             6 |
| private school  |               11 |             1 |
| long term care  |                9 |             1 |
:END:

It seems that =license_number= =0= is a generic Placeholder:
Most of these are related to /special events/, /churchs/, /festivals/
etc. But, What about  the =restaurants= which have =license_num= =
=0=? Are those the same restaurant?


#+BEGIN_SRC sql
  select
  license_num, facility, address, count(*) as total_inspections,
  coalesce(count(*) filter (where result = 'fail'), 0)
  as total_failures
  from cleaned.inspections
  where license_num = 0
  and facility_type = 'restaurant'
  group by  license_num, facility, address
  order by total_inspections desc
  limit 10
#+END_SRC

#+RESULTS:
:RESULTS:
| license_num | facility                        | address               | total_inspections | total_failures |
|------------+---------------------------------+-----------------------+------------------+---------------|
|          0 | british airways                 | 11601 w touhy ave     |                5 |             1 |
|          0 | rib lady 2                      | 4203 w cermak rd      |                4 |             3 |
|          0 | unlicensed                      | 7559 n ridge blvd     |                3 |             1 |
|          0 | nutricion familiar              | 3000 w 59th st        |                3 |             1 |
|          0 | taqueria la capital             | 3508 w 63rd st        |                3 |             1 |
|          0 | herbalife                       | 6214 w diversey ave   |                3 |             2 |
|          0 | las quecas                      | 2500 s christiana ave |                3 |             1 |
|          0 | la michoacana                   | 4346 s california ave |                3 |             1 |
|          0 | mrs. t's southern fried chicken | 3343 n broadway       |                3 |             1 |
|          0 | vinces pizzeria & taqueria, inc | 1527 w devon ave      |                3 |             1 |
:END:

Nope. We conclude that we can't use the =license_num= as the unique
identifier.

If we go back to the columns of the table, we could try with the
column =license_num=  (assume that one license represents one
establishment) and the column =address= (assume that one restaurant is
in one place).

#+BEGIN_SRC sql
  select
  count(distinct license_num) as total_licenses,
  count(distinct facility) as total_facilities,
  count(distinct address) as total_addresses
  from cleaned.inspections
#+END_SRC

#+RESULTS:
:RESULTS:
| total_licenses | total_facilities | total_addresses |
|---------------+-----------------+----------------|
|         33666 |           24937 |          17120 |
:END:

We were expecting (naively) that we should get one =license_num= per
=facility= per =address=, but it isn't the case. This could be mean that
several facilities share the name (e.g. "Subway" or "Mc Donalds")  or the
license; another explanation is that several facilities share the same
address, as the facilities at the stadium or the airport.

We will try to use the combination of =license_num=, =facility=, =facility_aka=,
=facility_type= and =address= to identify a facility:

#+BEGIN_SRC sql
select
license_num, facility, facility_type, facility_aka, address , count(*)
from cleaned.inspections
group by license_num, facility, facility_type, facility_aka, address
order by count(*) desc, facility, facility_aka, address, license_num, facility_type
limit 10
#+END_SRC

#+RESULTS:
:RESULTS:
| license_num | facility                     | facility_type  | facility_aka                  | address                   | count |
|------------+------------------------------+---------------+------------------------------+---------------------------+-------|
|    1490035 | mcdonald's                   | restaurant    | mcdonald's                   | 6900 s lafayette ave      |    46 |
|    1596210 | food 4 less midwest #552     | grocery store | food 4 less                  | 7030 s ashland ave        |    44 |
|    1142451 | jewel food  store # 3345     | grocery store | jewel food  store # 3345     | 1224 s wabash ave         |    41 |
|    1302136 | mcdonald's                   | restaurant    | mcdonald's                   | 70 e garfield blvd        |    40 |
|    1476553 | pete's produce               | grocery store | pete's produce               | 1543 e 87th st            |    40 |
|    2083833 | mariano's fresh market #8503 | grocery store | mariano's fresh market       | 333 e benton pl           |    39 |
|    1000572 | jewel food store #3030       | grocery store | jewel food store #3030       | 7530 s stony island ave   |    37 |
|       1094 | one stop food & liquor store | grocery store | one stop food & liquor store | 4301-4323 s lake park ave |    37 |
|      60184 | taqueria el ranchito         | restaurant    | taqueria el ranchito         | 2829 n milwaukee ave      |    37 |
|    1884255 | food 4 less                  | grocery store | food 4 less                  | 4821 w north ave          |    36 |
:END:

Which attributes should we add to the =entities= table? All the
attributes that describe the entity and doesn't depend on the
event and are atemporal. Therefore we will add =zip_code= and
=location=. We also will add =start_time, end_time= . These columns
describe the interval in which the facility is on business or /active/.

These columns will be important because we won't make predictions on
entities that aren't active.  

We don't have this type of date directly in our data source, so we
will use as an interval between the earliest date in the data source
and the latest date *or* the greater data in which  the *result* of the
inspection was =out of business= or =business not located=.

#+BEGIN_SRC sql :tangle ./sql/create_semantic_tables.sql

create schema if not exists semantic;

drop table if exists semantic.entities cascade;

create table semantic.entities as (

with entities_date as (

  select
  license_num,
  facility,
  facility_aka,
  facility_type,
  address,
  zip_code,
  location,
  min(date) over (partition by license_num, facility, facility_aka, address) as start_time,
  max(case when
  result in ('out of business', 'business not located')
  then
  date
  else
  NULL
  end) over (partition by license_num, facility, facility_aka, address) as end_time
  from cleaned.inspections

)

select distinct
   dense_rank() over (w) as entity_id,
   license_num,
   facility,
   facility_aka,
   facility_type,
   address,
   zip_code,
   location,
   start_time,
   end_time
from entities_date
   window w as (order by license_num, facility, facility_aka, facility_type, address)
);


-- Adding some indices
create index entities_ix on semantic.entities (entity_id);

create index entities_license_num_ix on semantic.entities (license_num);
create index entities_facility_ix on semantic.entities (facility);
create index entities_facility_type_ix on semantic.entities (facility_type);
create index entities_zip_code_ix on semantic.entities (zip_code);

-- Spatial index
create index entities_location_gix on semantic.entities using gist (location);

create index entities_full_key_ix on semantic.entities (license_num, facility, facility_aka, facility_type, address);

#+END_SRC

#+RESULTS:

Note that we add a /unique/ identifier (=entity_id=) to this table

#+BEGIN_SRC sql
select count(entity_id) from semantic.entities
#+END_SRC

#+RESULTS:
:RESULTS:
| count |
|-------|
| 34917 |
:END:


*** Events table

We are ready for creating our events table. This table will describe
the data related to the inspection, like /where/ and /when/ the
inspection happened, some attributes of the inspection as /type/ and
/result/, and we will add the violations as a =JSONB=
column[fn:11]. As a final detail we will rename the =inspection=
number to =event_id=[fn:13]  


#+begin_src sql :tangle ./sql/create_semantic_tables.sql

drop table if exists semantic.events cascade;

create table semantic.events as (

with entities as (
  select * from semantic.entities
),

inspections as (
select
i.inspection, i.type, i.date, i.risk, i.result,
i.license_num, i.facility, i.facility_aka, i.facility_type, i.address, i.zip_code, i.location,
jsonb_agg(
    jsonb_build_object(
        'code', v.code,
        'severity', v.severity,
	'description', v.description,
	'comment', v.comment
	)
order  by code
) as violations
from cleaned.inspections as i
inner join
cleaned.violations as v
on i.inspection = v.inspection
group by
i.inspection, i.type, i.license_num, i.facility, i.facility_aka, i.facility_type, i.address, i.zip_code, i.location,
i.date, i.risk, i.result
)

select
i.inspection as event_id, 
e.entity_id, i.type, i.date, i.risk, i.result,
e.facility_type, e.zip_code, e.location,
i.violations
from entities as e
inner join
inspections as i
using (license_num, facility, facility_aka, facility_type, address, zip_code)

);

-- Add some indices
create index events_entity_ix on semantic.events (entity_id);
create index events_event_ix on semantic.events (event_id);
create index events_type_ix on semantic.events (type);
create index events_date_ix on semantic.events(date desc nulls last);
create index events_facility_type_ix on semantic.events  (facility_type);
create index events_zip_code_ix on semantic.events  (zip_code);

-- Spatial index
create index events_location_gix on semantic.events using gist (location);

-- JSONB indices
create index events_violations on semantic.events using gin(violations);
create index events_violations_json_path on semantic.events using gin(violations jsonb_path_ops);

create index events_event_entity_zip_code_date on semantic.events (event_id desc nulls last, entity_id, zip_code, date desc nulls last);

#+end_src

#+RESULTS:

We accomplished to have one row per event[fn:12]. Our semantic data looks like:

#+begin_src sql
select event_id, entity_id, type, date, risk, result, facility_type, zip_code from semantic.events limit 1
#+end_src

#+RESULTS:
:RESULTS:
| event_id | entity_id | type    |       date | risk | result | facility_type | zip_code |
|---------+----------+---------+------------+------+--------+--------------+---------|
| 1343315 |        1 | canvass | 2013-06-06 | low  | fail   | newsstand    |   60623 |
:END:

We omitted =violations= and =location= for brevity. The total number of inspections is

#+BEGIN_SRC sql
select count(event_id) from semantic.events
#+END_SRC

#+RESULTS:
:RESULTS:
|  count |
|--------|
| 142248 |
:END:


* Footnotes

[fn:13] As a general rule I hate to add the suffix =_id=, I would
rather prefer to name them as =event= and =entity= instead of
=event_id= and =entity_id=. But =triage= named those columns in that
way and for that we are stuck with that nomenclature.

[fn:12] This will simplify the creation of /features/ for our machine learning models.

[fn:11] If you want to have a deep explanation about why is this good
check [[http://coussej.github.io/2016/01/14/Replacing-EAV-with-JSONB-in-PostgreSQL/][this blog post]]

[fn:10] We will store the =Point= as a =geography= object, in this way
all the spatial operation (like calculating the distances between two
facilities) will return answers in meters instead of degrees See for
example [[http://workshops.boundlessgeo.com/postgis-intro/geography.html][this.]]

[fn:9] As a real geographical object [[https://postgis.net/docs/ST_MakePoint.html][check the PostGIS documentation]]

[fn:8] It is the /Chicago/ Food Inspections dataset

[fn:7] This problem is related to the process of /deduplication/ and there will be another tutorial 
for that that uses anothe DSaPP tool: =pgdedup=.

[fn:6] Verbatim from the datasource documentation

[fn:5] It will make your life easier and most of the Machine Learning
algorithms only accept data in matrix form (i.e. one big table)

[fn:4] You could check that using the command =head= on =/data/inspections.csv=

[fn:3] If you are connected to the database, you could just type =select count(*) from raw.inspections=

[fn:2] /ibid/

[fn:1] You'll probably get a different number the data is updated every day.


* No export                                                        :noexport:

#+NAME: data_road
#+CAPTION: Data's transformation roadmap : from raw to triage
#+BEGIN_SRC ditaa :file images/data_road.png :cmdline -r -s 1.2 :export results
                   Data transformation roadmap
------------------------------------------------------------------ 
                       From raw to triage
                                                            
  +----------------+
  |    Chicago     |
  |Food Inspections|
  |cPNK  API   {io}|
  +-------+--------+
          | curl
          v                   
  +-------------+             
  | inspections |
  |     csv     |             
  |          {d}|             
  +------+------+             
         | psql \copy
         v
 +----------------+
 | raw.inspections|        sql
 |                +------------------+
 | cGRE           |                  |
 +-------+--------+                  |
         | sql                       |
         v                           v
+-------------------+      +----------------------+
|cleaned.inspections|      |   cleaned.violations |
|     cBLU          |      |        cBLU          |
+---------+---------+      +---------+------------+
          | sql                      | 
          +-------------------\      |
          |                   |      |
          |                   \------+
          |                          | sql
          v                          V
+-------------------+     +-------------------+ 
| semantic.entities |     |  semantic.events  |
|       c004        |     |       c004        |
+-------------------+     +-------------------+
         |                          |
         |           sql            |
         +-----+--------------+-----+          
               |              |            
---------------*--------------*---------------------------------
               |              |               specific to
               |              |             inspections or eis
               v              v
          +---------+     +---------+           /------------\
          |outcomes |.....| states  |...........|   needed   |     
          |     c1AB|     |     c1AB|           |     by cYEL|
          +---------+     +---------+           |   triage   |
               |              |                 \------------/
               |              |                        .
               \--+        +--/                        .
                  |        |                           .
                  v        v                 +-------------+  
               +--------------+              |  experiment |  
               |   triage {io}|              |    config   |
               |     run      |<-------------+          {d}|
               |cRED          |              |             |
               +------+-------+              +-------------+
                      |
                      |
                      v
                 +---------+
                 | results |
                 |c1FF  {s}|
                 +---------+

#+END_SRC
